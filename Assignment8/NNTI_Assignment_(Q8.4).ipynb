{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVaXo2-Ej5n6"
   },
   "source": [
    "# NNTI Assignment 8 (Q8.4)\n",
    "\n",
    "Name 1: <br>\n",
    "Student id 1: <br>\n",
    "Email 1: <br>\n",
    "\n",
    "Name 2: <br>\n",
    "Student id 2:  <br>\n",
    "Email 2:  <br>\n",
    "\n",
    "Name 3: <br>\n",
    "Student id 3:  <br>\n",
    "Email 3: <br>\n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook and the respective  files for any additional exercises necessary. There is no need to resubmit the data files should they be provided separately. <br>\n",
    "\n",
    "\n",
    "Upload the zipped folder on CMS. Please follow the naming convention of **Name1_id1_Name2_id2_Name3_id3.zip **. Only one member of the group should make the submisssion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMIwrvjY_1Xh"
   },
   "source": [
    "In this exercise you will build your own neural networks, but this time you need to add regularization in the form of dropout, weight-decay and early-stopping.\n",
    "\n",
    "Each layer should have the option of using dropout. Your code needs to allow for this flexibility.\n",
    "\n",
    "Additionally, adding weight-decay and early-stopping should also be optional upon creation.\n",
    "\n",
    "**NOTE**:\n",
    "1. You are allowed to use built-in functions from pytorch to incorporate this functionality.\n",
    "\n",
    "2. We recommend the use of GPUs or Google collab for this exercise.\n",
    "\n",
    "3. During training and validation, remember when to use `model.train()` and `model.eval()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zveJEhsAMxX"
   },
   "source": [
    "Use the below imports, as usual you are allowed to import additional packages, but mention the reason you're using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ1KJ4ybAMM9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9YGajyz__Y1"
   },
   "source": [
    "## a. Implement a regularized model [0.5 points]\n",
    "\n",
    "In this task, you will implement a custom neural network model using PyTorch. The model should incorporate key features such as **dropout** to improve generalization and prevent overfitting.\n",
    "\n",
    "**Tasks to implement**:\n",
    "\n",
    "1. Define the Model Architecture:\n",
    "  - The model consists of a series of fully connected (FC) layers with ReLU activations in between.\n",
    "  - Dropout layers are added after each hidden layer, with the probability of dropout specified by the `dropout_p` parameter.\n",
    "  - The final output layer produces a result that is passed through a Softmax activation for multi-class classification tasks.\n",
    "\n",
    "**Hint**:\n",
    "Since you're not implementing a CNN, but rather a simple ANN network, it is recommended to flatten your input images when pushing into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EECu_GiC_8rz"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network model incorporating dropout.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input features.\n",
    "        hidden_dim (int): Number of units in each hidden layer.\n",
    "        out_dim (int): Number of output units (number of classes).\n",
    "        num_layers (int): Number of hidden layers.\n",
    "        dropout (list of bool): Specifies which hidden layers will have dropout.\n",
    "        dropout_p (float): Dropout probability used for the Dropout layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, num_layers, dropout, dropout_p):\n",
    "      #TODO\n",
    "      pass\n",
    "\n",
    "    def forward(self, x):\n",
    "      #TODO\n",
    "      pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQjM-snFBJZs"
   },
   "source": [
    "### b. Data and code setup [1 + 0.25 + 0.25 = 1.5 points]\n",
    "\n",
    "You will use the MNIST dataset for these experiments. The data setup has been provided for you.<br> **DO NOT CHANGE THE CODE HERE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZipUQxVNBE9j",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# DO NOT CHANGE THE CODE IN THIS CELL\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(mnist_train))  # 80% for training\n",
    "val_size = len(mnist_train) - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset into training and validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_dl = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5xgR5zMgVCb"
   },
   "source": [
    "#### Training code\n",
    "The `trainer()` function trains a model using the provided data loaders, criterion (loss function), optimizer, and various options for regularization and early stopping. You will implement this function for training models for the experiments.\n",
    "\n",
    "Few things to keep in mind:\n",
    "- The function should accept model, data loaders, loss function, optimizer, and training configurations (epochs, early stopping).\n",
    "- The training loop should include forward pass, loss computation, backward pass, and weight update.\n",
    "- Track and return average training and validation losses for each epoch.\n",
    "- Use tqdm for progress bars during training and validation. (**optional**, but recommended)\n",
    "- Implement **early stopping** to halt training if validation loss doesn't improve for a set number of epochs. Provide a `patience` parameter as the number of epochs to wait until validation loss improves.\n",
    "  - Make it optional by passing a boolean param `early_stopping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRYujQeua3Sa"
   },
   "outputs": [],
   "source": [
    "def trainer(model, train_loader, val_loader, criterion, optimizer, epochs=50, early_stopping=False, patience=10):\n",
    "    \"\"\"\n",
    "    Train the model with optional early stopping.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        val_loader (DataLoader): The validation data loader.\n",
    "        criterion (loss function): The loss function.\n",
    "        optimizer (Optimizer): The optimizer to use.\n",
    "        epochs (int, optional): The number of epochs to train. Default is 50.\n",
    "        early_stopping (bool, optional): Whether to apply early stopping. Default is False.\n",
    "        patience (int, optional): The patience for early stopping. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        train_losses (list): List of average training losses per epoch.\n",
    "        val_losses (list): List of average validation losses per epoch.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaPYTUJ3hc32"
   },
   "source": [
    "#### Evaluation code\n",
    "\n",
    "Complete the `plot_losses()` function and `evaluate_model()` to visualize the training and validation losses and to evaluate the model over the test set.\n",
    "\n",
    "**NOTE**:\n",
    "1. Add a legend, title, and grid to improve plot readability for `plot_losses()`\n",
    "2. Report the average test loss, accuracy, and F1 score metrics using `evaluate_model()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1nQ7wF8a4V9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    Plot training and validation losses.\n",
    "\n",
    "    Args:\n",
    "        train_losses (list): List of average training losses per epoch.\n",
    "        val_losses (list): List of average validation losses per epoch.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set and report accuracy and F1 score.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to be evaluated.\n",
    "        test_loader (DataLoader): The test data loader.\n",
    "        criterion (loss function): The loss function to use for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        float: The average test loss.\n",
    "        float: The accuracy of the model on the test set.\n",
    "        float: The F1 score of the model on the test set.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8v0woWNgl5H"
   },
   "source": [
    "## c. Experiments: [0.25+0.25+0.25+0.25 = 1 point]\n",
    "Build a deep network using 3 hidden layers, so in total including input and output layers, it shoudl be a 5-layer network. You will run the following 4 experiments on this network with the given configurations:\n",
    "\n",
    "1. Deep network (at least 3 hidden layers)\n",
    "2. Deep regularized network (with weight-decay enabled)\n",
    "3. Deep regularized network (with weight-decay and dropout)\n",
    "4. Deep regularized network (with weight-decay and early-stopping)\n",
    "\n",
    "Report Accuracy and $F_1$ metrics on the `test set` for your experiments and discuss your results. What did you expect to see and what did you end up seeing.\n",
    "\n",
    "**NOTE**:\n",
    "- You can choose how you use regularization. Ideally you would experiment with various parameters for this regularization, the 4 listed variants are merely what you must cover as a minimum. You are free to run more experiments if you want to.\n",
    "- In the end, report results for all your experiments on the test set concisely  in a table at the end.\n",
    "- Use the Adam optimizer for all of your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfalnWsnaalz"
   },
   "source": [
    "### Experiment 1: Deep network (at least 3 hidden layers) (No Regularization)\n",
    "\n",
    "Use the given model configs and hyperparams to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpYAffBxaZC_"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Deep network (3 hidden layers) with no dropout and no weight-decay\n",
    "model_1_config = {\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"hidden_dim\": 400,\n",
    "    \"out_dim\": 10,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": [False, False, False],\n",
    "    \"dropout_p\": 0.5\n",
    "}\n",
    "\n",
    "\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0  # Use this only if weight-decay is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddIGJio2BfPb"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "# Plot the training and validation losses\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h95zrpJbMsI"
   },
   "source": [
    "### Experiment 2: Deep regularized network (with weight-decay enabled)\n",
    "\n",
    "Use the given model configs to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK6bMkMcbLFF"
   },
   "outputs": [],
   "source": [
    "# Deep network (3 hidden layers) with weight-decay but no dropout\n",
    "model_2_config = {\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"hidden_dim\": 400,\n",
    "    \"out_dim\": 10,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": [False, False, False],\n",
    "    \"dropout_p\": 0.5\n",
    "}\n",
    "\n",
    "\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-4  # Use this only if weight-decay is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-N_sB79bg4P"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "# Plot the training and validation losses\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84WAQN1ObnE7"
   },
   "source": [
    "### Experiment 3: Deep regularized network (with weight-decay and dropout)\n",
    "\n",
    "Use the given model configs to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue5pphPbbnE9"
   },
   "outputs": [],
   "source": [
    "# Deep regularized network (3 hidden layers) with weight-decay and dropout after every layer\n",
    "model_3_config = {\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"hidden_dim\": 400,\n",
    "    \"out_dim\": 10,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": [True, True, True],\n",
    "    \"dropout_p\": 0.5\n",
    "}\n",
    "\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-4  # Use this only if weight-decay is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpQ1bQZubnE9"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "# Plot the training and validation losses\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WooDkWWbzi-"
   },
   "source": [
    "### Experiment 4: Deep regularized network (with weight-decay and early-stopping)\n",
    "\n",
    "Use the given model configs to run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GR_soZtibzjA"
   },
   "outputs": [],
   "source": [
    "# Deep regularized network (3 hidden layers) with weight-decay and early stopping\n",
    "model_4_config = {\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"hidden_dim\": 400,\n",
    "    \"out_dim\": 10,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": [False, False, False],\n",
    "    \"dropout_p\": 0.5\n",
    "}\n",
    "\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-4  # Use this only if weight-decay is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuL1MKxVbzjA"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "# Plot the training and validation losses\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv9bvRimCPiL"
   },
   "outputs": [],
   "source": [
    "#Report the model accuracies and F1-score on the test set"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
